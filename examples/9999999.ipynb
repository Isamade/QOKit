{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Benchmarking of Parallel QAOA Portfolio Optimization with DWE\n",
    "\n",
    "This notebook systematically benchmarks the performance and solution quality of our parallel QAOA implementation for portfolio optimization, leveraging the Domain Wall Encoding (DWE) technique. As a telecom engineer with a mission to raise quantum technology awareness, this empirical data will be invaluable.\n",
    "\n",
    "We will evaluate how varying problem size, QAOA depth, optimizer effort, number of parallel processes, and transpilation levels impact both the time to solution and the quality of the results.\n",
    "\n",
    "**Key enhancements in this benchmarking notebook:**\n",
    "1.  **Systematic Parameter Variation:** We'll iterate through predefined ranges of `N`, `p`, `max_iterations_optimizer`, `num_parallel_runs`, and `Transpilation level`.\n",
    "2.  **Robust Data Collection:** Results from each run will be collected into a Pandas DataFrame.\n",
    "3.  **Comprehensive Metrics:** We'll track wall-clock time, solution energy, approximation ratio (where applicable), and details of each optimization attempt.\n",
    "4.  **Automated Visualization:** (Placeholder for future plots to illustrate trends and insights from the benchmarking data).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup, Imports, and Worker Function\n",
    "\n",
    "This section contains all necessary imports and the `run_single_optimization` worker function, originally from `qaoa_parallel_optimizer_worker.py`. This ensures the notebook is self-contained."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import concurrent.futures # For parallel processing (though we'll use multiprocessing.Pool)\n",
    "from multiprocessing import Pool # Explicitly use Pool for robustness\n",
    "import json\n",
    "import pandas as pd # For data collection and analysis\n",
    "import matplotlib.pyplot as plt # For visualization\n",
    "import itertools # For iterating over all parameter combinations\n",
    "\n",
    "from qokit.qaoa_circuit_portfolio import get_parameterized_qaoa_circuit\n",
    "from qiskit.circuit import ParameterVector, QuantumCircuit\n",
    "from qiskit import transpile\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# --- Qiskit Simulator Setup (integrated into worker for each process) ---\n",
    "# Note: The simulator needs to be initialized within each worker process if it's not picklable.\n",
    "# For AerSimulator, it's generally fine to create it once or pass it, but creating within\n",
    "# the worker function for Transpilation level changes is more robust.\n",
    "try:\n",
    "    from qiskit_aer import AerSimulator\n",
    "    GLOBAL_SIMULATOR_BACKEND = AerSimulator()\n",
    "    print(\"Initialized AerSimulator for global use (can be re-transpiled per worker).\")\n",
    "except ImportError:\n",
    "    try:\n",
    "        from qiskit.providers.aer import Aer\n",
    "        GLOBAL_SIMULATOR_BACKEND = Aer.get_backend('qasm_simulator')\n",
    "        print(\"Initialized Aer.get_backend('qasm_simulator') for global use.\")\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Qiskit Aer backend not found. Please install qiskit-aer (pip install qiskit-aer).\")\n",
    "\n",
    "\n",
    "# --- Cost Function for QAOA (from qaoa_parallel_optimizer_worker.py) ---\n",
    "def qaoa_cost_function(params, po_problem_arg, p_layers, num_shots_simulator, transpilation_level, cost_function_calls, simulator_backend):\n",
    "    \"\"\"\n",
    "    Computes the QAOA cost function for a given set of parameters (betas and gammas).\n",
    "    This function will be minimized by scipy.optimize.\n",
    "    \"\"\"\n",
    "    cost_function_calls[0] += 1  # Increment call counter\n",
    "\n",
    "    gammas = params[:p_layers]\n",
    "    betas = params[p_layers:]\n",
    "\n",
    "    qaoa_circuit = get_parameterized_qaoa_circuit(\n",
    "        po_problem=po_problem_arg,\n",
    "        depth=p_layers,\n",
    "        gamma=gammas,\n",
    "        beta=betas\n",
    "    )\n",
    "    qaoa_circuit.measure_all()\n",
    "\n",
    "    # Transpile for the simulator with specified optimization_level\n",
    "    transpiled_circuit = transpile(qaoa_circuit, simulator_backend, optimization_level=transpilation_level)\n",
    "\n",
    "    job = simulator_backend.run(transpiled_circuit, shots=num_shots_simulator)\n",
    "    result = job.result()\n",
    "    counts = result.get_counts(transpiled_circuit)\n",
    "\n",
    "    expected_energy = 0\n",
    "    total_shots = sum(counts.values())\n",
    "\n",
    "    if total_shots == 0:\n",
    "        print(f\"Warning: No shots recorded for bitstring counts in cost function. Counts: {counts}\")\n",
    "        return np.inf\n",
    "\n",
    "    J = po_problem_arg[\"J\"]\n",
    "    h = po_problem_arg[\"h\"]\n",
    "\n",
    "    for bitstring, count in counts.items():\n",
    "        x = np.array([int(b) for b in bitstring[::-1]])\n",
    "        energy_for_bitstring = 0\n",
    "\n",
    "        for i in range(len(x)):\n",
    "            for j in range(i + 1, len(x)):\n",
    "                if (i, j) in J:\n",
    "                    energy_for_bitstring += J[(i, j)] * x[i] * x[j]\n",
    "                elif (j, i) in J:\n",
    "                    energy_for_bitstring += J[(j, i)] * x[i] * x[j]\n",
    "\n",
    "        for i in range(len(x)):\n",
    "            if i in h:\n",
    "                energy_for_bitstring += h[i] * x[i]\n",
    "\n",
    "        expected_energy += energy_for_bitstring * count\n",
    "\n",
    "    return expected_energy / total_shots\n",
    "\n",
    "\n",
    "# --- Worker Function for Parallel Processing (from qaoa_parallel_optimizer_worker.py) ---\n",
    "def run_single_optimization(initial_point_tuple, po_problem_arg, p_layers, max_iterations_optimizer,\n",
    "                            num_shots_simulator, run_id, transpilation_level):\n",
    "    \"\"\"\n",
    "    Performs a single QAOA optimization run from a given initial point.\n",
    "    This function is designed to be run in parallel processes.\n",
    "    \"\"\"\n",
    "    start_time = time.perf_counter()\n",
    "    initial_point = np.array(initial_point_tuple)\n",
    "\n",
    "    # Initialize simulator within the worker for robustness with multiprocessing\n",
    "    try:\n",
    "        simulator = AerSimulator()\n",
    "    except ImportError:\n",
    "        from qiskit.providers.aer import Aer\n",
    "        simulator = Aer.get_backend('qasm_simulator')\n",
    "\n",
    "    print(f\"Run {run_id}: Starting optimization from initial point: {np.round(initial_point, 3)} with N={po_problem_arg['N']}, p={p_layers}, MaxIter={max_iterations_optimizer}, TL={transpilation_level}\")\n",
    "\n",
    "    cost_function_calls = [0]\n",
    "\n",
    "    try:\n",
    "        bounds = [(0, 2 * np.pi)] * p_layers + [(0, np.pi)] * p_layers\n",
    "\n",
    "        result = minimize(qaoa_cost_function, initial_point,\n",
    "                          args=(po_problem_arg, p_layers, num_shots_simulator, transpilation_level, cost_function_calls, simulator),\n",
    "                          method='COBYLA', bounds=bounds,\n",
    "                          options={'maxiter': max_iterations_optimizer, 'disp': False})\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        runtime = end_time - start_time\n",
    "\n",
    "        return {\n",
    "            \"run_id\": run_id,\n",
    "            \"optimal_params\": result.x.tolist(),\n",
    "            \"optimal_energy\": result.fun,\n",
    "            \"nfev\": result.nfev,\n",
    "            \"success\": result.success,\n",
    "            \"message\": result.message,\n",
    "            \"runtime_seconds\": runtime\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        end_time = time.perf_counter()\n",
    "        runtime = end_time - start_time\n",
    "        print(f\"Run {run_id}: Optimization failed - {e}\")\n",
    "        return {\n",
    "            \"run_id\": run_id,\n",
    "            \"optimal_energy\": float('inf'),\n",
    "            \"optimal_params\": None,\n",
    "            \"nfev\": cost_function_calls[0],\n",
    "            \"success\": False,\n",
    "            \"message\": str(e),\n",
    "            \"runtime_seconds\": runtime\n",
    "        }\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Benchmarking Parameters and Fixed Problem Setup\n",
    "\n",
    "Here, we define the ranges for the parameters we want to benchmark and set up the fixed problem parameters for the portfolio optimization with DWE."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Benchmarking Parameter Ranges ---\n",
    "num_parallel_runs_values = [1, 2, 3] # Number of parallel multi-start runs\n",
    "p_values = [1, 30, 60] # Number of QAOA layers (depth)\n",
    "max_iterations_optimizer_values = [50, 300 ,700] # Max iterations for classical optimizer\n",
    "N_values = [5, 8, 15] # Number of assets\n",
    "transpilation_level_values = [0, 3] # Transpilation optimization level\n",
    "\n",
    "# --- Fixed Problem Parameters ---\n",
    "num_shots_simulator = 256 # Number of shots for quantum circuit simulation\n",
    "q = 0.5 # Risk aversion parameter\n",
    "lambda_sum = 0 # DWE-inspired penalty coefficient for sum constraint.\n",
    "\n",
    "# Seed for reproducibility of problem definition (different for each N in benchmark, if desired)\n",
    "PROBLEM_SEED = 42 # For consistent portfolio problem generation across runs if N is fixed\n",
    "\n",
    "# --- Helper Function to Define Portfolio Optimization Problem (as in your original notebook) ---\n",
    "def define_po_problem(N_val, K_val, q_val, lambda_sum_val, problem_seed=None):\n",
    "    if problem_seed is not None:\n",
    "        np.random.seed(problem_seed)\n",
    "\n",
    "    mu = np.random.uniform(0.05, 0.20, N_val)\n",
    "    Sigma = np.random.uniform(0.001, 0.015, (N_val, N_val))\n",
    "    Sigma = (Sigma + Sigma.T) / 2 # Make it symmetric\n",
    "    Sigma = Sigma + np.eye(N_val) * 0.005 # Add a small diagonal component for stability\n",
    "\n",
    "    factor_J_obj = (2 * q_val) / (K_val**2)\n",
    "    factor_h_linear_obj = -1 / K_val\n",
    "    factor_h_diagonal_obj = q_val / (K_val**2)\n",
    "\n",
    "    J_coeffs_objective = {}\n",
    "    h_coeffs_objective = {}\n",
    "\n",
    "    for i in range(N_val):\n",
    "        for j in range(i + 1, N_val):\n",
    "            J_coeffs_objective[(i, j)] = factor_J_obj * Sigma[i, j]\n",
    "\n",
    "    for i in range(N_val):\n",
    "        h_coeffs_objective[i] = factor_h_linear_obj * mu[i] + factor_h_diagonal_obj * Sigma[i, i]\n",
    "\n",
    "    J_coeffs_total = {}\n",
    "    h_coeffs_total = {}\n",
    "\n",
    "    for (i, j), val in J_coeffs_objective.items():\n",
    "        J_coeffs_total[(i, j)] = val + 2 * lambda_sum_val\n",
    "\n",
    "    for i, val in h_coeffs_objective.items():\n",
    "        h_coeffs_total[i] = val - 5 * lambda_sum_val\n",
    "\n",
    "    po_problem_dict = {\n",
    "        \"N\": N_val,\n",
    "        \"K\": K_val,\n",
    "        \"q\": q_val,\n",
    "        \"J\": J_coeffs_total,\n",
    "        \"h\": h_coeffs_total,\n",
    "        \"means\": mu,\n",
    "        \"cov\": Sigma,\n",
    "        \"q_orig\": q_val,\n",
    "        \"scale\": 1.0\n",
    "    }\n",
    "    return po_problem_dict, mu, Sigma # Return mu and Sigma for brute-force if needed\n",
    "\n",
    "# Function to evaluate the classical objective energy for a given bitstring\n",
    "def evaluate_bitstring_energy(bitstring_array, original_mu, original_Sigma, original_q):\n",
    "    x = bitstring_array\n",
    "    portfolio_variance = np.dot(x, np.dot(original_Sigma, x))\n",
    "    portfolio_return = np.dot(original_mu, x)\n",
    "    return original_q * portfolio_variance - portfolio_return\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Benchmarking Execution Loop\n",
    "\n",
    "This is the main section that orchestrates the benchmarking. It iterates through all combinations of parameters, runs the parallel QAOA optimization, collects the results, and stores them in a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if __name__ == \"__main__\":\n",
    "    all_benchmarking_results = []\n",
    "\n",
    "    # Create a list of all parameter combinations\n",
    "    param_combinations = itertools.product(\n",
    "        num_parallel_runs_values,\n",
    "        p_values,\n",
    "        max_iterations_optimizer_values,\n",
    "        N_values,\n",
    "        transpilation_level_values\n",
    "    )\n",
    "\n",
    "    total_runs_count = len(num_parallel_runs_values) * \\\n",
    "                       len(p_values) * \\\n",
    "                       len(max_iterations_optimizer_values) * \\\n",
    "                       len(N_values) * \\\n",
    "                       len(transpilation_level_values)\n",
    "\n",
    "    print(f\"Total benchmarking configurations to run: {total_runs_count}\")\n",
    "    current_run_idx = 0\n",
    "\n",
    "    for current_num_parallel_runs, current_p, current_max_iter, current_N, current_transpilation_level in param_combinations:\n",
    "        current_run_idx += 1\n",
    "        print(f\"\\n--- Starting Benchmarking Run {current_run_idx}/{total_runs_count} ---\")\n",
    "        print(f\"Parameters: num_parallel_runs={current_num_parallel_runs}, p={current_p}, max_iter={current_max_iter}, N={current_N}, TL={current_transpilation_level}\")\n",
    "\n",
    "        # --- Define Problem Parameters dynamically for current N ---\n",
    "        current_K = int(current_N * 0.4)\n",
    "        po_problem, mu_for_bruteforce, cov_for_bruteforce = define_po_problem(\n",
    "            current_N, current_K, q, lambda_sum, problem_seed=PROBLEM_SEED\n",
    "        )\n",
    "\n",
    "        # --- Calculate Brute-Force Classical Optimal Energy (if feasible) ---\n",
    "        E_min_classical = None\n",
    "        E_max_classical = None\n",
    "        if current_N <= 20: # Keep brute-force limited for practical runtime\n",
    "            try:\n",
    "                from qokit.portfolio_optimization import portfolio_brute_force\n",
    "                original_po_problem_for_brute_force = {\n",
    "                    \"N\":current_N, \"K\":current_K, \"q\":q, \"means\":mu_for_bruteforce, \"cov\":cov_for_bruteforce, \"scale\": 1.0\n",
    "                }\n",
    "                E_min_classical, E_max_classical = portfolio_brute_force(original_po_problem_for_brute_force, return_bitstring=False)\n",
    "                print(f\"Brute-force E_min: {E_min_classical:.6f}, E_max: {E_max_classical:.6f}\")\n",
    "            except ImportError:\n",
    "                print(\"qokit.portfolio_optimization.portfolio_brute_force not available.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Brute-force calculation failed for N={current_N}: {e}\")\n",
    "        else:\n",
    "            print(f\"Brute-force calculation skipped for N={current_N} (too large).\")\n",
    "\n",
    "        # --- Generate Initial Points for Multi-Start ---\n",
    "        initial_points = []\n",
    "        np.random.seed(current_run_idx) # Use run_idx as seed for initial points to ensure variety\n",
    "        for _ in range(current_num_parallel_runs):\n",
    "            gammas_initial = np.random.uniform(0, 2 * np.pi, current_p)\n",
    "            betas_initial = np.random.uniform(0, np.pi, current_p)\n",
    "            initial_points.append(tuple(np.concatenate((gammas_initial, betas_initial))))\n",
    "\n",
    "        # --- Parallel Execution ---\n",
    "        start_overall_time = time.perf_counter()\n",
    "\n",
    "        worker_args = [(initial_point, po_problem, current_p, current_max_iter, num_shots_simulator, i + 1, current_transpilation_level)\n",
    "                       for i, initial_point in enumerate(initial_points)]\n",
    "\n",
    "        individual_run_results = []\n",
    "        try:\n",
    "            with Pool(processes=os.cpu_count()) as pool:\n",
    "                results = [pool.apply_async(run_single_optimization, args) for args in worker_args]\n",
    "\n",
    "                for future in results:\n",
    "                    individual_run_results.append(future.get())\n",
    "        except Exception as e:\n",
    "            print(f\"Error during parallel execution for current configuration: {e}\")\n",
    "            # Append a partial result to indicate failure for this config\n",
    "            individual_run_results = [{'success': False, 'message': str(e), 'optimal_energy': float('inf'), 'runtime_seconds': (time.perf_counter() - start_overall_time)}]\n",
    "\n",
    "        end_overall_time = time.perf_counter()\n",
    "        overall_duration = end_overall_time - start_overall_time\n",
    "        print(f\"All parallel optimization runs for current config completed in {overall_duration:.2f} seconds.\")\n",
    "\n",
    "        # --- Process and Summarize Results for current config ---\n",
    "        best_overall_energy = float('inf')\n",
    "        best_overall_params = None\n",
    "        num_successful_individual_runs = 0\n",
    "        all_individual_energies = []\n",
    "\n",
    "        if individual_run_results:\n",
    "            for result in individual_run_results:\n",
    "                if result['success']:\n",
    "                    num_successful_individual_runs += 1\n",
    "                    all_individual_energies.append(result['optimal_energy'])\n",
    "                if result['optimal_energy'] < best_overall_energy:\n",
    "                    best_overall_energy = result['optimal_energy']\n",
    "                    best_overall_params = result['optimal_params']\n",
    "\n",
    "        approximation_ratio = None\n",
    "        if E_min_classical is not None and E_max_classical is not None and (E_max_classical - E_min_classical) != 0:\n",
    "            approximation_ratio = (best_overall_energy - E_min_classical) / (E_max_classical - E_min_classical)\n",
    "        elif E_min_classical is not None and E_max_classical is not None and (E_max_classical - E_min_classical) == 0:\n",
    "            # Special case for AR when range is zero (all solutions are optimal)\n",
    "            approximation_ratio = 0.0 if best_overall_energy == E_min_classical else np.inf # Or handle as NaN\n",
    "\n",
    "        # Store results for this configuration\n",
    "        config_results = {\n",
    "            'N': current_N,\n",
    "            'K': current_K,\n",
    "            'p': current_p,\n",
    "            'num_parallel_runs': current_num_parallel_runs,\n",
    "            'max_iterations_optimizer': current_max_iter,\n",
    "            'num_shots_simulator': num_shots_simulator,\n",
    "            'q': q,\n",
    "            'lambda_sum': lambda_sum,\n",
    "            'transpilation_level': current_transpilation_level,\n",
    "            'overall_runtime_seconds': overall_duration,\n",
    "            'best_overall_energy': best_overall_energy,\n",
    "            'approximation_ratio': approximation_ratio,\n",
    "            'E_min_classical': E_min_classical,\n",
    "            'E_max_classical': E_max_classical,\n",
    "            'num_successful_individual_runs': num_successful_individual_runs,\n",
    "            'total_individual_runs_attempted': current_num_parallel_runs,\n",
    "            'all_individual_energies': all_individual_energies # Store for detailed analysis if needed\n",
    "        }\n",
    "        all_benchmarking_results.append(config_results)\n",
    "\n",
    "    print(\"\\n--- Benchmarking Completed ---\")\n",
    "    # Convert results to a Pandas DataFrame\n",
    "    results_df = pd.DataFrame(all_benchmarking_results)\n",
    "    print(\"\\nBenchmarking Results DataFrame Head:\")\n",
    "    print(results_df.head())\n",
    "\n",
    "    # Optional: Save results to CSV or other format\n",
    "    # results_df.to_csv(\"qaoa_benchmarking_results.csv\", index=False)\n",
    "    # print(\"Results saved to qaoa_benchmarking_results.csv\")\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results Analysis and Visualization (Future)\n",
    "\n",
    "This section is where you would perform analysis on the `results_df` and create visualizations to understand the impact of varying parameters on performance and solution quality.\n",
    "\n",
    "### Example Analysis Ideas:\n",
    "- Plot `overall_runtime_seconds` vs. `N` (for different `p` values).\n",
    "- Plot `best_overall_energy` vs. `p` (for different `N` values).\n",
    "- Plot `approximation_ratio` vs. `max_iterations_optimizer`.\n",
    "- Analyze the success rate (`num_successful_individual_runs / total_individual_runs_attempted`).\n",
    "- Create heatmaps or 3D plots to show interactions between multiple parameters.\n",
    "\n",
    "You can use libraries like `matplotlib.pyplot` and `seaborn` for creating insightful plots."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example of basic plotting (uncomment and run after the main loop finishes)\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for N_val in N_values:\n",
    "#     subset = results_df[results_df['N'] == N_val]\n",
    "#     plt.plot(subset['p'], subset['best_overall_energy'], label=f'N={N_val}')\n",
    "# plt.xlabel('QAOA Layers (p)')\n",
    "# plt.ylabel('Best Overall Energy')\n",
    "# plt.title('Best Energy vs. QAOA Layers for different N')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# You can also save the DataFrame to a CSV for external analysis:\n",
    "# results_df.to_csv('qaoa_benchmarking_results.csv', index=False)\n",
    "# print(\"Benchmarking results saved to 'qaoa_benchmarking_results.csv'\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
